1. RPC
   RPC框架通过提供一种透明的调用机制,让使用者不必显式区分本地调用和远程调用,从而让构建分布式计算or应用更加方便
   RPC调用分为同步和异步调用两种,同步调用指客户端发起调用后,等待执行结果的返回,异步调用指客户端不用等待执行返回,可以通过回调等方式获取结果
2. 正则表达式描述了一种字符串匹配的模式
   正则中的非打印字符:\f 换页符; \n 换行符; \r 回车符; \s 任意空白字符,包括空格,制表符,换页符等; \S 任意非空白符,等价于[^\f\n\r\t\v];
   \t 制表符; \v 垂直制表符
   正则中的特殊字符:$ 字符串的结尾位置; ^ 字符串的开始位置; () 子表达式的开始和结束位置,在中括号表达式中表示不在该集合中;
   * 匹配前面的子表达式零次或多次; + 匹配前面的子表达式一次或多次; ? 匹配前面的子表达式零次或一次; . 匹配除换行符\n以为的任意一个字符; 
   [] 中括号表达式; | 两项之间的一个
   正则中的限定符,表示表达式中的一个组件,必须要出现多少次才能满足匹配,除了*/+/?之外,还包括{n},{n,},{n,m}
   注: * + 限定符都是贪婪的,它们会尽可能多的匹配字符,只有在它们后面加上'?',就可以实现非贪婪或者最小匹配
   正则中的定位符,用来描述字符串或单词的边界, ^/$ 表示字符串的开始和结束; \b 描述单词的前/后边界; \B 非单词边界
3. 需要在另外一台电脑上checkout一些文件,输入地址&账号&密码后,TortoiseSVN提示:
   Unable to connect to a repository atu URL "xxxxxxx" Access to '/svn/xxx' forbidden
   在网上查了一下,SVN --> Settings --> Saved Data --> 几个相关的clear按钮点一下,之后重新checkout,bingo...
   参考:https://blog.csdn.net/wx_lanyu/article/details/84207303
4. 记录两个sublime的快捷键
    一个是常用的Ctrl+D,选中文本,当有多个的时候,或者想只选中其中的几个的时候,常用的是该快捷键,如果想对所有文本进行操作,一个一个选显然太low,
    可替代的就是先选中文本,再Alt+F3,即可选中全部文本;
    另一个是列操作,常用的是Ctrl+Alt+上下箭头,后边遇到个情况,需要多从mysql中导出的1w多条记录进行列操作,这时候一直按箭头显然也不现实,
    可替代的是先Ctrl+A选中所有的记录,再Ctrl+Shift+L ('L'大小写均可)
5. 从系统架构来看,目前的服务器可分为三大体系结构,分别是对称多处理器(SMP),非一致存储访问(NUMA)以及海量并行处理(MPP)
   SMP(Symmetric Multi Processor),所谓的对称是指多个cpu对称工作,没有主次和从属关系,因此SMP也被称为一直存储访问结构(UMA,Uniform Memory Access)
   对称多处理器系统内有很多紧耦合多处理器,所有的CPU共享总线,内存,I/O等系统资源,因此该系统最大的特点就是共享所有的资源
   cpu之间没有区别,平等的访问内存,外设,共用一个操作系统,操作系统管理一个队列,每个处理器依次处理队列中的进程,如果两个处理器同时访问一个资源
   (同一段内存地址),由硬/软件的锁机制处理资源争用问题,对SMP的扩展方式包括增加内存和cpu,更换更快的cpu,扩充I/O;
   NUMA(Non-uniform Memory Access)非一致存储访问架构,是一种为多处理器电脑设计的内存架构,内存访问时间取决于处理的内存位置,NUMA服务器的基本特征是
   具有多个cpu模块,每个cpu模块又有多个cpu组成,并且具有独立的本地内存和I/O槽口,由于节点之间可以通过互联模块(crossbar switch)进行连接和信息交互,
   因此每个cpu都可以访问整个系统内存,显然访问本地内存的速度远远高于访问其它节点内存的速度,这也就是非一致的由来,NUMA的主要缺陷也在于此,当添加多个
   cpu模块时系统性能无法线性增加;
   MMP(Massive Parallel Processing)与NUMA不同,MPP提供了另外一种扩展系统的方式,其基本结构是由多个SMP服务器(称之为节点),通过节点互联网络连接而成,
   每个SMP节点只访问自己的本地资源,是一种完全无共享的结构,在MPP系统中,每个SMP节点也可以运行自己的内存,总线,操作系统和数据库等,
   与NUMA不同的是,MPP不存在访问其它节点内存的问题,节点之间的信息交互是通过互联网络实现的,这个过程一般称之为数据重分配(Data Redistribution)
   参考:http://www.elecfans.com/baike/computer/fuwuqi/20171023568144.html
6. Protocol buff编码格式及sxxx的zigzag编码:
   https://www.cnblogs.com/cobbliu/archive/2013/03/02/2940074.html
   https://izualzhy.cn/protobuf-encode-varint-and-zigzag#4-zigzag%E7%BC%96%E7%A0%81
   protocol buff的数据类型:
   VARIINT 可变长度整型,该类型数据使用varint编码对所传入的数据进行压缩存储,int32/64,uint32/64,sint32/64,bool,enum属该类型
   FIXED32/64 固定长度整型,不会对传入的数据进行varint压缩,只存储原始数据,fixed32,sfixed32,float属FIXED32,fixed64,sfixed64,double属FIXED64
   LENGTH_DELIMITED 长度界定型数据,主要针对string,bytes,embedded messages,packed repeated field,简言之就是针对string类型,repeated和嵌套
   类型,对这些类型数据进行编码时需要保存它们的长度信息
   START_GROUP 组的开始标志,组也可以是repeated或嵌套类型
   END_GROUP 组的结束标志,其余同上
7. 待挖掘的: https://www.jianshu.com/u/38eb16b24cb9 
8. SIMD(Single Instruction Multiple Data)
9. 栈帧(Stack Frame)
    在数据结构中,栈是限定只能在表尾进行插入或删除操作的线性表,是按照后进先出存储数据的一种数据结构,在计算机系统中,栈也称为栈内存,是一块动态内存区域,
    栈用于维护函数调用的上下文,包括函数内部的局部变量,函数调用,函数参数值及返回值等,栈由系统分配,存储地址连续且有上限,因此存在栈溢出现象
    每一次函数的调用都会在调用栈(call stack)上维护一个独立的栈帧,每个栈帧包括以下几个部分:
    a> 函数的返回地址和参数;
    b> 临时变量,包括函数内部的非静态局部变量和编译器生成的其它临时变量
    c> 函数调用的上下文,一个函数的栈帧由ebp和esp这两个寄存器来划定范围,ebp指向当前栈帧底部,ebp寄存器又称为帧指针,esp指向栈帧顶部,
       esp寄存器又称为栈指针,函数的调用过程中,有调用者(caller)和被调用者(callee),调用者需要知道被调用者的返回值,被调用者需要知道传入的参数和
       返回地址
    函数的调用过程:
    a> 参数入栈,将参数从右向左依次压入系统栈中
    b> 返回地址入栈,将当前代码区调用指令的下一条指令地址压入栈中
    c> 代码区跳转,处理器从当前代码区跳转到被调用函数的入口处
    d> 栈帧调整,具体包括:
        1> 将当前栈帧的ebp入栈
        2> 将esp装入ebp,切换当前栈帧到新栈帧(ebp,esp这两个寄存器指定了当前栈帧)
        3> 给新栈帧分配空间,通常是sub指令(栈内存地址从高到低,当前站定esp执行sub xxx,则往低地址移动)
    e> 在新栈帧执行当前被调用的函数
    函数的返回过程:
    a> 保存返回值,通常将返回值保存在寄存器EAX中
    b> 弹出当前栈帧,恢复调用函数的栈帧,具体包括:
        1> 在堆栈平衡的基础上,给esp加上栈帧大小(执行函数调用时栈帧调整第2步的相反操作),降低栈顶,回收当前栈空间
        2> 将当前栈顶保存的前栈帧ebp弹出并装入ebp寄存器
        3> 将当前栈顶的返回地址(要执行的下一条指令地址)弹给EIP寄存器(此时esp又回到了函数调用前的位置)
    c> 跳转,按照函数返回地址跳回母函数中继续执行
    esp(extended stack pointer)栈指针寄存器,该指针永远指向系统栈最上面一个栈帧(当前运行函数的栈帧)的顶部
    ebp(extended base pointer)基址指针寄存器,同esp,永远指向系统栈最上面一个栈帧的底部
    eip(extended instruction pointer)指令寄存器,该指针永远指向下一条待执行的指令地址,控制了eip就控制了进程,eip的内容决定了cpu会去哪里执行命令
    参考:
      https://www.cnblogs.com/dwlsxj/p/Stack.html
      https://blog.csdn.net/SKI_12/article/details/80554677
10. 必看书籍:深入理解计算机系统,程序员的自我修养
11. 经典GC(garbage collection)算法
    a> 引用计数(reference counting),每个单元维护一个域,保存其它单元指向它的引用数量,当引用数量为0时,将它回收,引用计数的有点是:渐进式,内存管理
       与用户程序的执行交织在一起,内存管理的开销分散到整个程序运行之中(c++的share_ptr使用的就是引用计数),不像标记-清除算法需要STW(stop the 
       world,GC时挂起用户程序); 算法易于实现; 内存单元很快被回收,不像其它算法,堆被耗尽或者达到某个阈值时才会进行垃圾回收
       引用计数算法的缺点是:原始的引用计数不能处理循环引用,针对该问题,有给出的解决方案,比如强引用; 维护引用计数,降低程序运行效率,内存的更新删除等
       操作,都需要维护相关内存单元的引用计数; 内存单元池实现方式(free_list)不是cache-friendly,会导致频繁的cache-miss,降低运行效率
    b> 标记-清除(mark sweep),是第一种自动内存管理,基于追踪的垃圾收集算法,内存单元并不会在变成垃圾内存时立即回收,而是保持不可达状态,直到达到某个
       阈值或者到固定时间,此时系统挂起用户程序(STW),转而执行垃圾回收程序,回收程序对所有存活内存单元进行一次全局扫描,确定哪些可以回收,算法分为两步:
       标记阶段,扫描并确认所有可回收的内存单元,清除阶段,将垃圾内存单元回收,标记-清除算法的优点是避免了引用计数算法的缺点(不能处理循环引用,需要维护
       引用计数),缺点是需要STW
    c> 三色标记算法(tricolor mark-sweep algorithm),三色标记算法是对描述阶段的改进,原理如下:
       初始所有内存对象均为白色; 从根对象(全局对象,线程栈)出发扫描所有可达对象,标记为灰色,放入待处理队列; 从队列取出灰色对象,将其引用对象标记为
       灰色,并放入队列,找到所有引用对象或无引用对象后,将当前灰色对象标记为黑色; 重复上一步骤,直至队列为空,此时白色对象即为垃圾内存,进行回收
       Go的三次标记算法流程:
       初始状态下,进程空间里每个内存对象都是白色,扫描开始前,先做一次短暂的STW,将扫描任务作为多个并发的goroutine立即入队给调度器,第一轮先扫描所有
       可达的内存对象,标记灰色并放入处理队列,第二轮start the world,取上一步的灰色队列,扫描其引用对象加入队列,并置黑,直至队列为空,第三轮再次STW,
       对上一个处理过程中新增/更新的内存进行标记(使用了操作系统的写屏障,write barrier),mark完毕,start the world,并发执行sweep操作
       go的gc需要注意mark有两个过程:
         首先从root开始遍历,root包括全局指针和goroutine栈上的指针,标记为灰色,并遍历灰色队列;
         re-scan全局指针和栈,因为mark和用户程序是并行的(开始mark时有一个极短的STW),所以在第一次遍历过程中可能会有新的内存对象或内存对象的更新,
         此时需要通过写屏障记录下来,re-scan再检查一遍;
       STW也有两个过程:
         第一次上文有提到过,就是在GC要开始的时候,主要做一些准备工作,包括:enable write barrier;
         第二次就是上文的re-scan过程,这个过程如果不STW,则有可能又会产生新的对象生成or更新,这样会导致无止尽的mark,所以此时STW,挂起用户程序
         Go的垃圾回收还存在一种情况,扫描的速度跟不上回收的速度,这将导致内存膨胀,比如多核系统中,3个核执行用户程序,1个核执行gc,这样就有可能出现上述
         情况,解决办法是,当Go发现回收速度跟不上分配速度的时候,会把其它运行用户程序的核抢过来做垃圾回收,造成事实上的STW,此时可全力进行垃圾回收
    d> 节点复制,也是基于追踪的算法,将整个堆等分为两个半区(semi-space),一个是Fromspace,一个是Tospace,节点复制会切换两个半区的角色,初始时,所有活动
       对象都在Fromspace,gc开始时,扫描Fromspace,将活动(被引用)对象复制到Tospace,遍历完Fromspace之后,所有活动对象都在Tospace,释放内存时,直接释放
       Fromspace即可,切换Fromspace/Tospace角色,用户程序可以继续运行,算法优点是:所有存活的数据结构,都缩并的排列在Tospace底部,这样不存在内存碎片的
       问题; 获取新内存可以简单的通过递增自由空间指针来获得,算法最大的缺点是,内存得不到充分利用,总有一半空间处于浪费状态 
    e> 分代收集(generational garbage collection),基于追踪的垃圾回收算法存在一个问题,在生命周期较长的对象上浪费时间(生命周期较长的对象不需要频繁
       扫描),同时,内存分配存在一个事实,"most object die young"(大多数对象会很快被回收),基于这两点,分代垃圾回收将内存对象按生命周期长短存放到堆
       的两个(或者多个)区域上,这个区域就是分代,新对象就在新生代中分配,如果gc扫描发现该对象已被扫描过,则将该对对象移到老年代,这个过程叫promote,
       随着不断promote,新生代在堆中的占比不会特别大,gc回收主要集中在新生代,回收的效率也会比较高,STW的时间更短,新生代的回收频率要比老年代高
       erlang采用该算法进行垃圾回收,同时基于erlang线程避免了STW,erlang:garbage_collect/0/1/2对当前or指定进程进行垃圾回收,可以通过环境变量
       ERL_FULLSWEEP_AFTER及erlang:system_flag(fullsweep_after,Number)设置Number次浅扫描后,触发深度扫描
12. HTTP缓存:https://mp.weixin.qq.com/s?__biz=MzUzMjk0ODI0OA==&mid=2247483754&idx=1&sn=5882213a4c48c6938ce5029f9b267a27&chksm=faaa351dcdddbc0bd3a6eb69f9e1fe6711a39320737c1db6035296037fc8a9b677b4c98a62dd&token=1212449367&lang=zh_CN&scene=21#wechat_redirect
